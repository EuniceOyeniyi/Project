{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "import os, sys, glob, pickle\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout,\n",
    "                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation, Input, Dense)\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Other  \n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import scipy\n",
    "from scipy.stats import skew\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import os\n",
    "import sys\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3 as pt\n",
    "import speech_recognition as sr\n",
    "import pywhatkit\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.system(\"clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>female_disgust</td>\n",
       "      <td>../SER/CREMA/1061_IWL_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>male_fear</td>\n",
       "      <td>../SER/CREMA/1019_TAI_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>male_calm</td>\n",
       "      <td>../SER/CREMA/1083_IOM_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10827</th>\n",
       "      <td>female_disgust</td>\n",
       "      <td>../SER/SER-Ravdess-data/Actor_02/03-01-07-01-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8022</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>../SER/CREMA/1059_DFA_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Emotion                                               Path\n",
       "8222   female_disgust                   ../SER/CREMA/1061_IWL_DIS_XX.wav\n",
       "4797        male_fear                   ../SER/CREMA/1019_TAI_FEA_XX.wav\n",
       "10010       male_calm                   ../SER/CREMA/1083_IOM_NEU_XX.wav\n",
       "10827  female_disgust  ../SER/SER-Ravdess-data/Actor_02/03-01-07-01-0...\n",
       "8022         male_sad                   ../SER/CREMA/1059_DFA_SAD_XX.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df = pd.read_csv('combined_data.csv')\n",
    "audio_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df_copy = audio_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male_angry', 'male_happy', 'male_calm', 'male_sad',\n",
       "       'female_angry', 'female_happy', 'female_calm', 'female_sad'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df.Emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = audio_df_copy[audio_df_copy['Emotion']=='female_disgust'].index\n",
    "audio_df_copy.drop(todrop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, n, mfcc):\n",
    "    sampling_rate=44100\n",
    "    audio_duration=2.5\n",
    "\n",
    "\n",
    "    X = np.empty(shape=(df.shape[0], n, 216, 1))\n",
    "    input_length = sampling_rate * audio_duration\n",
    "    \n",
    "    cnt = 0\n",
    "    for fname in tqdm(df.Path):\n",
    "        file_path = fname\n",
    "        data, _ = librosa.load(file_path, sr=sampling_rate\n",
    "                               ,res_type=\"kaiser_fast\"\n",
    "                               ,duration=2.5\n",
    "                               ,offset=0.5\n",
    "                              )\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, int(input_length) - len(data) - offset), \"constant\")\n",
    "\n",
    "                \n",
    "        # which feature?\n",
    "        if mfcc == 1:\n",
    "            # MFCC extraction \n",
    "            MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n",
    "            MFCC = np.expand_dims(MFCC, axis=-1)\n",
    "            X[cnt,] = MFCC\n",
    "            \n",
    "        else:\n",
    "            # Log-melspectogram\n",
    "            melspec = librosa.feature.melspectrogram(data, n_mels = n_melspec)   \n",
    "            logspec = librosa.amplitude_to_db(melspec)\n",
    "            logspec = np.expand_dims(logspec, axis=-1)\n",
    "            X[cnt,] = logspec\n",
    "            \n",
    "        cnt += 1\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7664/7664 [11:29<00:00, 11.12it/s]\n"
     ]
    }
   ],
   "source": [
    "n_mfcc = 30\n",
    "mfcc = prepare_data(audio_df_copy, n = n_mfcc, aug = 0, mfcc = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7664, 30, 216, 1)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(mfcc\n",
    "                                                    , audio_df_copy.Emotion\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n",
    "\n",
    "# one hot encode the target \n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1916, 8)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "180/180 - 153s - loss: 1.8103 - acc: 0.3173 - val_loss: 1.7406 - val_acc: 0.3706 - 153s/epoch - 847ms/step\n",
      "Epoch 2/150\n",
      "180/180 - 155s - loss: 1.3391 - acc: 0.4843 - val_loss: 1.7861 - val_acc: 0.3408 - 155s/epoch - 862ms/step\n",
      "Epoch 3/150\n",
      "180/180 - 150s - loss: 1.1262 - acc: 0.5743 - val_loss: 1.4492 - val_acc: 0.4802 - 150s/epoch - 836ms/step\n",
      "Epoch 4/150\n",
      "180/180 - 150s - loss: 1.0141 - acc: 0.6103 - val_loss: 1.3281 - val_acc: 0.5678 - 150s/epoch - 835ms/step\n",
      "Epoch 5/150\n",
      "180/180 - 150s - loss: 0.9349 - acc: 0.6491 - val_loss: 0.7946 - val_acc: 0.6931 - 150s/epoch - 835ms/step\n",
      "Epoch 6/150\n",
      "180/180 - 150s - loss: 0.8881 - acc: 0.6548 - val_loss: 0.8431 - val_acc: 0.6748 - 150s/epoch - 834ms/step\n",
      "Epoch 7/150\n",
      "180/180 - 149s - loss: 0.8453 - acc: 0.6815 - val_loss: 0.9695 - val_acc: 0.6096 - 149s/epoch - 830ms/step\n",
      "Epoch 8/150\n",
      "180/180 - 151s - loss: 0.8163 - acc: 0.6872 - val_loss: 0.7266 - val_acc: 0.7135 - 151s/epoch - 836ms/step\n",
      "Epoch 9/150\n",
      "180/180 - 151s - loss: 0.7750 - acc: 0.7074 - val_loss: 0.8763 - val_acc: 0.6634 - 151s/epoch - 838ms/step\n",
      "Epoch 10/150\n",
      "180/180 - 150s - loss: 0.7642 - acc: 0.7070 - val_loss: 0.7932 - val_acc: 0.6900 - 150s/epoch - 831ms/step\n",
      "Epoch 11/150\n",
      "180/180 - 149s - loss: 0.7315 - acc: 0.7218 - val_loss: 0.8638 - val_acc: 0.6613 - 149s/epoch - 828ms/step\n",
      "Epoch 12/150\n",
      "180/180 - 151s - loss: 0.7073 - acc: 0.7319 - val_loss: 1.0411 - val_acc: 0.5981 - 151s/epoch - 841ms/step\n",
      "Epoch 13/150\n",
      "180/180 - 150s - loss: 0.6796 - acc: 0.7500 - val_loss: 0.9413 - val_acc: 0.6253 - 150s/epoch - 831ms/step\n",
      "Epoch 14/150\n",
      "180/180 - 150s - loss: 0.6626 - acc: 0.7550 - val_loss: 0.7609 - val_acc: 0.7062 - 150s/epoch - 835ms/step\n",
      "Epoch 15/150\n",
      "180/180 - 148s - loss: 0.6553 - acc: 0.7550 - val_loss: 0.7793 - val_acc: 0.6848 - 148s/epoch - 824ms/step\n",
      "Epoch 16/150\n",
      "180/180 - 152s - loss: 0.6426 - acc: 0.7561 - val_loss: 0.7756 - val_acc: 0.6947 - 152s/epoch - 845ms/step\n",
      "Epoch 17/150\n",
      "180/180 - 142s - loss: 0.6164 - acc: 0.7693 - val_loss: 0.8348 - val_acc: 0.7020 - 142s/epoch - 788ms/step\n",
      "Epoch 18/150\n",
      "180/180 - 148s - loss: 0.5912 - acc: 0.7757 - val_loss: 0.8567 - val_acc: 0.6696 - 148s/epoch - 824ms/step\n",
      "Epoch 19/150\n",
      "180/180 - 146s - loss: 0.5883 - acc: 0.7724 - val_loss: 0.7520 - val_acc: 0.7082 - 146s/epoch - 811ms/step\n",
      "Epoch 20/150\n",
      "180/180 - 147s - loss: 0.5575 - acc: 0.7871 - val_loss: 0.8189 - val_acc: 0.6921 - 147s/epoch - 818ms/step\n",
      "Epoch 21/150\n",
      "180/180 - 147s - loss: 0.5569 - acc: 0.7794 - val_loss: 0.7577 - val_acc: 0.7067 - 147s/epoch - 815ms/step\n",
      "Epoch 22/150\n",
      "180/180 - 142s - loss: 0.5341 - acc: 0.7944 - val_loss: 1.4782 - val_acc: 0.5360 - 142s/epoch - 788ms/step\n",
      "Epoch 23/150\n",
      "180/180 - 140s - loss: 0.5221 - acc: 0.8003 - val_loss: 0.9956 - val_acc: 0.6701 - 140s/epoch - 780ms/step\n",
      "Epoch 24/150\n",
      "180/180 - 140s - loss: 0.5127 - acc: 0.8006 - val_loss: 0.8556 - val_acc: 0.6801 - 140s/epoch - 778ms/step\n",
      "Epoch 25/150\n",
      "180/180 - 140s - loss: 0.4717 - acc: 0.8257 - val_loss: 0.6079 - val_acc: 0.7547 - 140s/epoch - 779ms/step\n",
      "Epoch 26/150\n",
      "180/180 - 142s - loss: 0.4715 - acc: 0.8224 - val_loss: 0.7524 - val_acc: 0.7140 - 142s/epoch - 789ms/step\n",
      "Epoch 27/150\n",
      "180/180 - 141s - loss: 0.4567 - acc: 0.8253 - val_loss: 0.7221 - val_acc: 0.7281 - 141s/epoch - 785ms/step\n",
      "Epoch 28/150\n",
      "180/180 - 139s - loss: 0.4310 - acc: 0.8361 - val_loss: 0.7381 - val_acc: 0.7338 - 139s/epoch - 775ms/step\n",
      "Epoch 29/150\n",
      "180/180 - 143s - loss: 0.4197 - acc: 0.8445 - val_loss: 0.8381 - val_acc: 0.7135 - 143s/epoch - 793ms/step\n",
      "Epoch 30/150\n",
      "180/180 - 141s - loss: 0.4027 - acc: 0.8530 - val_loss: 0.6210 - val_acc: 0.7641 - 141s/epoch - 786ms/step\n",
      "Epoch 31/150\n",
      "180/180 - 141s - loss: 0.3934 - acc: 0.8519 - val_loss: 0.6470 - val_acc: 0.7620 - 141s/epoch - 782ms/step\n",
      "Epoch 32/150\n",
      "180/180 - 140s - loss: 0.3784 - acc: 0.8575 - val_loss: 0.7080 - val_acc: 0.7343 - 140s/epoch - 776ms/step\n",
      "Epoch 33/150\n",
      "180/180 - 141s - loss: 0.3985 - acc: 0.8530 - val_loss: 0.6737 - val_acc: 0.7406 - 141s/epoch - 785ms/step\n",
      "Epoch 34/150\n",
      "180/180 - 140s - loss: 0.3614 - acc: 0.8617 - val_loss: 0.8198 - val_acc: 0.7229 - 140s/epoch - 775ms/step\n",
      "Epoch 35/150\n",
      "180/180 - 141s - loss: 0.3478 - acc: 0.8700 - val_loss: 0.6719 - val_acc: 0.7557 - 141s/epoch - 786ms/step\n",
      "Epoch 36/150\n",
      "180/180 - 141s - loss: 0.3347 - acc: 0.8728 - val_loss: 0.7702 - val_acc: 0.7255 - 141s/epoch - 782ms/step\n",
      "Epoch 37/150\n",
      "180/180 - 141s - loss: 0.3145 - acc: 0.8836 - val_loss: 0.6667 - val_acc: 0.7636 - 141s/epoch - 785ms/step\n",
      "Epoch 38/150\n",
      "180/180 - 142s - loss: 0.3210 - acc: 0.8840 - val_loss: 0.6612 - val_acc: 0.7594 - 142s/epoch - 791ms/step\n",
      "Epoch 39/150\n",
      "180/180 - 142s - loss: 0.3125 - acc: 0.8862 - val_loss: 0.7493 - val_acc: 0.7448 - 142s/epoch - 790ms/step\n",
      "Epoch 40/150\n",
      "180/180 - 141s - loss: 0.3010 - acc: 0.8887 - val_loss: 1.0102 - val_acc: 0.6811 - 141s/epoch - 781ms/step\n",
      "Epoch 41/150\n",
      "180/180 - 141s - loss: 0.2992 - acc: 0.8925 - val_loss: 0.7330 - val_acc: 0.7510 - 141s/epoch - 782ms/step\n",
      "Epoch 42/150\n",
      "180/180 - 141s - loss: 0.2956 - acc: 0.8963 - val_loss: 0.6618 - val_acc: 0.7766 - 141s/epoch - 783ms/step\n",
      "Epoch 43/150\n",
      "180/180 - 142s - loss: 0.2836 - acc: 0.8920 - val_loss: 0.9074 - val_acc: 0.7255 - 142s/epoch - 789ms/step\n",
      "Epoch 44/150\n",
      "180/180 - 141s - loss: 0.2865 - acc: 0.8981 - val_loss: 0.8384 - val_acc: 0.7406 - 141s/epoch - 784ms/step\n",
      "Epoch 45/150\n",
      "180/180 - 142s - loss: 0.2673 - acc: 0.9017 - val_loss: 0.8965 - val_acc: 0.7140 - 142s/epoch - 790ms/step\n",
      "Epoch 46/150\n",
      "180/180 - 142s - loss: 0.2567 - acc: 0.9080 - val_loss: 0.7382 - val_acc: 0.7495 - 142s/epoch - 790ms/step\n",
      "Epoch 47/150\n",
      "180/180 - 139s - loss: 0.2622 - acc: 0.9021 - val_loss: 0.8294 - val_acc: 0.7401 - 139s/epoch - 775ms/step\n",
      "Epoch 48/150\n",
      "180/180 - 141s - loss: 0.2237 - acc: 0.9179 - val_loss: 0.7753 - val_acc: 0.7698 - 141s/epoch - 783ms/step\n",
      "Epoch 49/150\n",
      "180/180 - 140s - loss: 0.2484 - acc: 0.9081 - val_loss: 0.6611 - val_acc: 0.7761 - 140s/epoch - 775ms/step\n",
      "Epoch 50/150\n",
      "180/180 - 141s - loss: 0.2165 - acc: 0.9259 - val_loss: 0.7859 - val_acc: 0.7542 - 141s/epoch - 786ms/step\n",
      "Epoch 51/150\n",
      "180/180 - 141s - loss: 0.2298 - acc: 0.9179 - val_loss: 0.7613 - val_acc: 0.7589 - 141s/epoch - 781ms/step\n",
      "Epoch 52/150\n",
      "180/180 - 142s - loss: 0.2225 - acc: 0.9168 - val_loss: 0.7101 - val_acc: 0.7688 - 142s/epoch - 791ms/step\n",
      "Epoch 53/150\n",
      "180/180 - 141s - loss: 0.2232 - acc: 0.9189 - val_loss: 0.9779 - val_acc: 0.7474 - 141s/epoch - 783ms/step\n",
      "Epoch 54/150\n",
      "180/180 - 142s - loss: 0.2271 - acc: 0.9148 - val_loss: 0.7707 - val_acc: 0.7641 - 142s/epoch - 787ms/step\n",
      "Epoch 55/150\n",
      "180/180 - 140s - loss: 0.2104 - acc: 0.9231 - val_loss: 0.8695 - val_acc: 0.7406 - 140s/epoch - 778ms/step\n",
      "Epoch 56/150\n",
      "180/180 - 141s - loss: 0.2058 - acc: 0.9269 - val_loss: 1.1681 - val_acc: 0.6822 - 141s/epoch - 782ms/step\n",
      "Epoch 57/150\n",
      "180/180 - 141s - loss: 0.2207 - acc: 0.9210 - val_loss: 0.7745 - val_acc: 0.7573 - 141s/epoch - 784ms/step\n",
      "Epoch 58/150\n",
      "180/180 - 140s - loss: 0.1944 - acc: 0.9316 - val_loss: 0.7793 - val_acc: 0.7630 - 140s/epoch - 780ms/step\n",
      "Epoch 59/150\n",
      "180/180 - 142s - loss: 0.1987 - acc: 0.9320 - val_loss: 0.8385 - val_acc: 0.7584 - 142s/epoch - 789ms/step\n",
      "Epoch 60/150\n",
      "180/180 - 141s - loss: 0.1767 - acc: 0.9348 - val_loss: 0.7829 - val_acc: 0.7620 - 141s/epoch - 784ms/step\n",
      "Epoch 61/150\n",
      "180/180 - 141s - loss: 0.1747 - acc: 0.9360 - val_loss: 0.7979 - val_acc: 0.7745 - 141s/epoch - 781ms/step\n",
      "Epoch 62/150\n",
      "180/180 - 142s - loss: 0.1748 - acc: 0.9360 - val_loss: 0.8910 - val_acc: 0.7594 - 142s/epoch - 787ms/step\n",
      "Epoch 63/150\n",
      "180/180 - 143s - loss: 0.1811 - acc: 0.9349 - val_loss: 0.7810 - val_acc: 0.7730 - 143s/epoch - 793ms/step\n",
      "Epoch 64/150\n",
      "180/180 - 144s - loss: 0.1922 - acc: 0.9309 - val_loss: 0.9124 - val_acc: 0.7568 - 144s/epoch - 799ms/step\n",
      "Epoch 65/150\n",
      "180/180 - 140s - loss: 0.1722 - acc: 0.9384 - val_loss: 0.8627 - val_acc: 0.7589 - 140s/epoch - 777ms/step\n",
      "Epoch 66/150\n",
      "180/180 - 140s - loss: 0.1648 - acc: 0.9400 - val_loss: 0.7705 - val_acc: 0.7698 - 140s/epoch - 780ms/step\n",
      "Epoch 67/150\n",
      "180/180 - 142s - loss: 0.1708 - acc: 0.9398 - val_loss: 0.8741 - val_acc: 0.7636 - 142s/epoch - 790ms/step\n",
      "Epoch 68/150\n",
      "180/180 - 140s - loss: 0.1610 - acc: 0.9402 - val_loss: 0.8710 - val_acc: 0.7557 - 140s/epoch - 780ms/step\n",
      "Epoch 69/150\n",
      "180/180 - 143s - loss: 0.1620 - acc: 0.9421 - val_loss: 0.8858 - val_acc: 0.7610 - 143s/epoch - 794ms/step\n",
      "Epoch 70/150\n",
      "180/180 - 140s - loss: 0.1620 - acc: 0.9415 - val_loss: 0.9630 - val_acc: 0.7479 - 140s/epoch - 779ms/step\n",
      "Epoch 71/150\n",
      "180/180 - 143s - loss: 0.1621 - acc: 0.9447 - val_loss: 0.9469 - val_acc: 0.7364 - 143s/epoch - 794ms/step\n",
      "Epoch 72/150\n",
      "180/180 - 139s - loss: 0.1646 - acc: 0.9414 - val_loss: 0.8204 - val_acc: 0.7662 - 139s/epoch - 774ms/step\n",
      "Epoch 73/150\n",
      "180/180 - 141s - loss: 0.1599 - acc: 0.9475 - val_loss: 0.8580 - val_acc: 0.7651 - 141s/epoch - 783ms/step\n",
      "Epoch 74/150\n",
      "180/180 - 140s - loss: 0.1522 - acc: 0.9480 - val_loss: 0.8630 - val_acc: 0.7693 - 140s/epoch - 778ms/step\n",
      "Epoch 75/150\n",
      "180/180 - 141s - loss: 0.1446 - acc: 0.9489 - val_loss: 0.8682 - val_acc: 0.7625 - 141s/epoch - 783ms/step\n",
      "Epoch 76/150\n",
      "180/180 - 142s - loss: 0.1532 - acc: 0.9421 - val_loss: 0.8387 - val_acc: 0.7563 - 142s/epoch - 790ms/step\n",
      "Epoch 77/150\n",
      "180/180 - 141s - loss: 0.1517 - acc: 0.9464 - val_loss: 0.9423 - val_acc: 0.7630 - 141s/epoch - 785ms/step\n",
      "Epoch 78/150\n",
      "180/180 - 141s - loss: 0.1436 - acc: 0.9501 - val_loss: 0.8566 - val_acc: 0.7698 - 141s/epoch - 786ms/step\n",
      "Epoch 79/150\n",
      "180/180 - 140s - loss: 0.1361 - acc: 0.9482 - val_loss: 0.9897 - val_acc: 0.7552 - 140s/epoch - 779ms/step\n",
      "Epoch 80/150\n",
      "180/180 - 142s - loss: 0.1286 - acc: 0.9535 - val_loss: 0.8033 - val_acc: 0.7641 - 142s/epoch - 791ms/step\n",
      "Epoch 81/150\n",
      "180/180 - 140s - loss: 0.1518 - acc: 0.9461 - val_loss: 0.8603 - val_acc: 0.7547 - 140s/epoch - 777ms/step\n",
      "Epoch 82/150\n",
      "180/180 - 141s - loss: 0.1430 - acc: 0.9495 - val_loss: 0.8747 - val_acc: 0.7745 - 141s/epoch - 784ms/step\n",
      "Epoch 83/150\n",
      "180/180 - 141s - loss: 0.1427 - acc: 0.9546 - val_loss: 0.8689 - val_acc: 0.7698 - 141s/epoch - 785ms/step\n",
      "Epoch 84/150\n",
      "180/180 - 141s - loss: 0.1246 - acc: 0.9574 - val_loss: 0.8739 - val_acc: 0.7787 - 141s/epoch - 784ms/step\n",
      "Epoch 85/150\n",
      "180/180 - 141s - loss: 0.1131 - acc: 0.9619 - val_loss: 0.8458 - val_acc: 0.7719 - 141s/epoch - 783ms/step\n",
      "Epoch 86/150\n",
      "180/180 - 140s - loss: 0.1225 - acc: 0.9548 - val_loss: 0.9118 - val_acc: 0.7636 - 140s/epoch - 776ms/step\n",
      "Epoch 87/150\n",
      "180/180 - 140s - loss: 0.1568 - acc: 0.9497 - val_loss: 0.8961 - val_acc: 0.7667 - 140s/epoch - 779ms/step\n",
      "Epoch 88/150\n",
      "180/180 - 140s - loss: 0.1189 - acc: 0.9579 - val_loss: 0.8839 - val_acc: 0.7599 - 140s/epoch - 779ms/step\n",
      "Epoch 89/150\n",
      "180/180 - 145s - loss: 0.1241 - acc: 0.9582 - val_loss: 0.9247 - val_acc: 0.7777 - 145s/epoch - 807ms/step\n",
      "Epoch 90/150\n",
      "180/180 - 143s - loss: 0.1274 - acc: 0.9572 - val_loss: 0.7996 - val_acc: 0.7683 - 143s/epoch - 794ms/step\n",
      "Epoch 91/150\n",
      "180/180 - 141s - loss: 0.1146 - acc: 0.9589 - val_loss: 0.8979 - val_acc: 0.7677 - 141s/epoch - 781ms/step\n",
      "Epoch 92/150\n",
      "180/180 - 142s - loss: 0.1174 - acc: 0.9584 - val_loss: 0.7955 - val_acc: 0.7745 - 142s/epoch - 787ms/step\n",
      "Epoch 93/150\n",
      "180/180 - 141s - loss: 0.1122 - acc: 0.9614 - val_loss: 0.8291 - val_acc: 0.7850 - 141s/epoch - 783ms/step\n",
      "Epoch 94/150\n",
      "180/180 - 142s - loss: 0.1155 - acc: 0.9569 - val_loss: 0.9756 - val_acc: 0.7568 - 142s/epoch - 787ms/step\n",
      "Epoch 95/150\n",
      "180/180 - 142s - loss: 0.1113 - acc: 0.9598 - val_loss: 1.1785 - val_acc: 0.7552 - 142s/epoch - 789ms/step\n",
      "Epoch 96/150\n",
      "180/180 - 141s - loss: 0.1163 - acc: 0.9621 - val_loss: 1.0663 - val_acc: 0.7422 - 141s/epoch - 782ms/step\n",
      "Epoch 97/150\n",
      "180/180 - 140s - loss: 0.1351 - acc: 0.9508 - val_loss: 0.9249 - val_acc: 0.7615 - 140s/epoch - 781ms/step\n",
      "Epoch 98/150\n",
      "180/180 - 140s - loss: 0.1140 - acc: 0.9600 - val_loss: 0.9294 - val_acc: 0.7803 - 140s/epoch - 779ms/step\n",
      "Epoch 99/150\n",
      "180/180 - 143s - loss: 0.1247 - acc: 0.9582 - val_loss: 0.9627 - val_acc: 0.7589 - 143s/epoch - 795ms/step\n",
      "Epoch 100/150\n",
      "180/180 - 140s - loss: 0.1280 - acc: 0.9565 - val_loss: 0.8698 - val_acc: 0.7761 - 140s/epoch - 776ms/step\n",
      "Epoch 101/150\n",
      "180/180 - 141s - loss: 0.1119 - acc: 0.9612 - val_loss: 0.9169 - val_acc: 0.7698 - 141s/epoch - 786ms/step\n",
      "Epoch 102/150\n",
      "180/180 - 141s - loss: 0.1202 - acc: 0.9591 - val_loss: 1.1087 - val_acc: 0.7390 - 141s/epoch - 784ms/step\n",
      "Epoch 103/150\n",
      "180/180 - 142s - loss: 0.1056 - acc: 0.9654 - val_loss: 0.8777 - val_acc: 0.7761 - 142s/epoch - 787ms/step\n",
      "Epoch 104/150\n",
      "180/180 - 140s - loss: 0.1047 - acc: 0.9635 - val_loss: 0.8708 - val_acc: 0.7641 - 140s/epoch - 780ms/step\n",
      "Epoch 105/150\n",
      "180/180 - 142s - loss: 0.1031 - acc: 0.9635 - val_loss: 0.9302 - val_acc: 0.7704 - 142s/epoch - 787ms/step\n",
      "Epoch 106/150\n",
      "180/180 - 141s - loss: 0.1075 - acc: 0.9636 - val_loss: 1.0920 - val_acc: 0.7411 - 141s/epoch - 783ms/step\n",
      "Epoch 107/150\n",
      "180/180 - 141s - loss: 0.1112 - acc: 0.9616 - val_loss: 0.8907 - val_acc: 0.7657 - 141s/epoch - 783ms/step\n",
      "Epoch 108/150\n",
      "180/180 - 142s - loss: 0.1076 - acc: 0.9633 - val_loss: 1.1049 - val_acc: 0.7411 - 142s/epoch - 792ms/step\n",
      "Epoch 109/150\n",
      "180/180 - 140s - loss: 0.1011 - acc: 0.9635 - val_loss: 0.9373 - val_acc: 0.7615 - 140s/epoch - 779ms/step\n",
      "Epoch 110/150\n",
      "180/180 - 141s - loss: 0.1009 - acc: 0.9664 - val_loss: 0.7928 - val_acc: 0.7688 - 141s/epoch - 786ms/step\n",
      "Epoch 111/150\n",
      "180/180 - 144s - loss: 0.1008 - acc: 0.9643 - val_loss: 0.9731 - val_acc: 0.7787 - 144s/epoch - 802ms/step\n",
      "Epoch 112/150\n",
      "180/180 - 145s - loss: 0.1005 - acc: 0.9692 - val_loss: 0.9296 - val_acc: 0.7735 - 145s/epoch - 803ms/step\n",
      "Epoch 113/150\n",
      "180/180 - 147s - loss: 0.1002 - acc: 0.9647 - val_loss: 0.9678 - val_acc: 0.7891 - 147s/epoch - 817ms/step\n",
      "Epoch 114/150\n",
      "180/180 - 145s - loss: 0.0961 - acc: 0.9666 - val_loss: 1.1161 - val_acc: 0.7479 - 145s/epoch - 805ms/step\n",
      "Epoch 115/150\n",
      "180/180 - 144s - loss: 0.0996 - acc: 0.9694 - val_loss: 0.9511 - val_acc: 0.7704 - 144s/epoch - 800ms/step\n",
      "Epoch 116/150\n",
      "180/180 - 145s - loss: 0.1088 - acc: 0.9635 - val_loss: 1.0075 - val_acc: 0.7542 - 145s/epoch - 805ms/step\n",
      "Epoch 117/150\n",
      "180/180 - 146s - loss: 0.0939 - acc: 0.9696 - val_loss: 0.9740 - val_acc: 0.7589 - 146s/epoch - 809ms/step\n",
      "Epoch 118/150\n",
      "180/180 - 145s - loss: 0.0877 - acc: 0.9696 - val_loss: 0.9418 - val_acc: 0.7547 - 145s/epoch - 807ms/step\n",
      "Epoch 119/150\n",
      "180/180 - 146s - loss: 0.1157 - acc: 0.9622 - val_loss: 1.0750 - val_acc: 0.7537 - 146s/epoch - 809ms/step\n",
      "Epoch 120/150\n",
      "180/180 - 144s - loss: 0.1108 - acc: 0.9595 - val_loss: 0.9926 - val_acc: 0.7688 - 144s/epoch - 799ms/step\n",
      "Epoch 121/150\n",
      "180/180 - 141s - loss: 0.1122 - acc: 0.9614 - val_loss: 1.0330 - val_acc: 0.7751 - 141s/epoch - 784ms/step\n",
      "Epoch 122/150\n",
      "180/180 - 141s - loss: 0.0851 - acc: 0.9683 - val_loss: 0.9984 - val_acc: 0.7683 - 141s/epoch - 785ms/step\n",
      "Epoch 123/150\n",
      "180/180 - 140s - loss: 0.1012 - acc: 0.9671 - val_loss: 0.8410 - val_acc: 0.7740 - 140s/epoch - 780ms/step\n",
      "Epoch 124/150\n",
      "180/180 - 141s - loss: 0.0812 - acc: 0.9727 - val_loss: 1.0123 - val_acc: 0.7745 - 141s/epoch - 786ms/step\n",
      "Epoch 125/150\n",
      "180/180 - 140s - loss: 0.0908 - acc: 0.9696 - val_loss: 1.0399 - val_acc: 0.7469 - 140s/epoch - 780ms/step\n",
      "Epoch 126/150\n",
      "180/180 - 142s - loss: 0.1019 - acc: 0.9624 - val_loss: 0.8516 - val_acc: 0.7782 - 142s/epoch - 789ms/step\n",
      "Epoch 127/150\n",
      "180/180 - 141s - loss: 0.0947 - acc: 0.9668 - val_loss: 1.1612 - val_acc: 0.7662 - 141s/epoch - 782ms/step\n",
      "Epoch 128/150\n",
      "180/180 - 144s - loss: 0.0782 - acc: 0.9720 - val_loss: 0.9234 - val_acc: 0.7844 - 144s/epoch - 799ms/step\n",
      "Epoch 129/150\n",
      "180/180 - 142s - loss: 0.0742 - acc: 0.9741 - val_loss: 1.0020 - val_acc: 0.7751 - 142s/epoch - 787ms/step\n",
      "Epoch 130/150\n",
      "180/180 - 140s - loss: 0.0849 - acc: 0.9716 - val_loss: 0.9522 - val_acc: 0.7740 - 140s/epoch - 776ms/step\n",
      "Epoch 131/150\n",
      "180/180 - 140s - loss: 0.0999 - acc: 0.9654 - val_loss: 0.9544 - val_acc: 0.7824 - 140s/epoch - 779ms/step\n",
      "Epoch 132/150\n",
      "180/180 - 140s - loss: 0.0940 - acc: 0.9692 - val_loss: 1.0030 - val_acc: 0.7787 - 140s/epoch - 781ms/step\n",
      "Epoch 133/150\n",
      "180/180 - 142s - loss: 0.0829 - acc: 0.9718 - val_loss: 1.0435 - val_acc: 0.7625 - 142s/epoch - 787ms/step\n",
      "Epoch 134/150\n",
      "180/180 - 142s - loss: 0.0998 - acc: 0.9675 - val_loss: 1.0736 - val_acc: 0.7677 - 142s/epoch - 791ms/step\n",
      "Epoch 135/150\n",
      "180/180 - 142s - loss: 0.0839 - acc: 0.9722 - val_loss: 0.9463 - val_acc: 0.7803 - 142s/epoch - 791ms/step\n",
      "Epoch 136/150\n",
      "180/180 - 140s - loss: 0.0793 - acc: 0.9718 - val_loss: 0.9858 - val_acc: 0.7735 - 140s/epoch - 778ms/step\n",
      "Epoch 137/150\n",
      "180/180 - 142s - loss: 0.0916 - acc: 0.9683 - val_loss: 1.0502 - val_acc: 0.7563 - 142s/epoch - 789ms/step\n",
      "Epoch 138/150\n",
      "180/180 - 141s - loss: 0.0788 - acc: 0.9743 - val_loss: 1.1691 - val_acc: 0.7547 - 141s/epoch - 784ms/step\n",
      "Epoch 139/150\n",
      "180/180 - 141s - loss: 0.0911 - acc: 0.9682 - val_loss: 0.9557 - val_acc: 0.7636 - 141s/epoch - 782ms/step\n",
      "Epoch 140/150\n",
      "180/180 - 141s - loss: 0.0837 - acc: 0.9716 - val_loss: 1.0374 - val_acc: 0.7484 - 141s/epoch - 782ms/step\n",
      "Epoch 141/150\n",
      "180/180 - 143s - loss: 0.0771 - acc: 0.9713 - val_loss: 0.9821 - val_acc: 0.7787 - 143s/epoch - 792ms/step\n",
      "Epoch 142/150\n",
      "180/180 - 140s - loss: 0.0752 - acc: 0.9760 - val_loss: 0.8914 - val_acc: 0.7803 - 140s/epoch - 776ms/step\n",
      "Epoch 143/150\n",
      "180/180 - 142s - loss: 0.0775 - acc: 0.9723 - val_loss: 1.1063 - val_acc: 0.7411 - 142s/epoch - 789ms/step\n",
      "Epoch 144/150\n",
      "180/180 - 142s - loss: 0.0892 - acc: 0.9683 - val_loss: 0.9858 - val_acc: 0.7756 - 142s/epoch - 788ms/step\n",
      "Epoch 145/150\n",
      "180/180 - 144s - loss: 0.0926 - acc: 0.9687 - val_loss: 1.0598 - val_acc: 0.7625 - 144s/epoch - 802ms/step\n",
      "Epoch 146/150\n",
      "180/180 - 141s - loss: 0.0962 - acc: 0.9683 - val_loss: 0.9378 - val_acc: 0.7724 - 141s/epoch - 784ms/step\n",
      "Epoch 147/150\n",
      "180/180 - 141s - loss: 0.0720 - acc: 0.9765 - val_loss: 1.1015 - val_acc: 0.7630 - 141s/epoch - 782ms/step\n",
      "Epoch 148/150\n",
      "180/180 - 142s - loss: 0.0785 - acc: 0.9746 - val_loss: 0.9764 - val_acc: 0.7761 - 142s/epoch - 786ms/step\n",
      "Epoch 149/150\n",
      "180/180 - 141s - loss: 0.0858 - acc: 0.9708 - val_loss: 1.0723 - val_acc: 0.7636 - 141s/epoch - 785ms/step\n",
      "Epoch 150/150\n",
      "180/180 - 141s - loss: 0.0852 - acc: 0.9701 - val_loss: 0.9671 - val_acc: 0.7709 - 141s/epoch - 782ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalization as per the standard NN process\n",
    "def get_2d_conv_model(n):\n",
    "    ''' Create a standard deep 2D convolutional neural network'''\n",
    "    nclass = 8\n",
    "    inp = Input(shape=(n,216,1))  #2D matrix of 30 MFCC bands by 216 audio length.\n",
    "    x = Convolution2D(64, (2,10), padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(64\n",
    "    , (2,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(64\n",
    "    , (2,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(64\n",
    "    , (2,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    \n",
    "    opt = optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# Build CNN model \n",
    "model = get_2d_conv_model(n=n_mfcc)\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                    batch_size=32, verbose = 2, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 21s 170ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 0, 5, ..., 4, 7, 0], dtype=int64)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test, \n",
    "                         batch_size=16, \n",
    "                         verbose=1)\n",
    "\n",
    "preds=preds.argmax(axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.astype(int).flatten()\n",
    "preds = (lb.inverse_transform((preds)))\n",
    "preds = pd.DataFrame({'predictedvalues': preds})\n",
    "\n",
    "\n",
    "# Actual labels\n",
    "actual=y_test.argmax(axis=1)\n",
    "actual = actual.astype(int).flatten()\n",
    "actual = (lb.inverse_transform((actual)))\n",
    "actual = pd.DataFrame({'actualvalues': actual})\n",
    "\n",
    "# Lets combined both of them into a single dataframe\n",
    "finaldf = actual.join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>female_angry</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>female_angry</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>male_calm</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>male_calm</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actualvalues predictedvalues\n",
       "1294  female_angry    female_angry\n",
       "1024  female_angry    female_angry\n",
       "994     female_sad      female_sad\n",
       "63    female_happy    female_happy\n",
       "1892    female_sad      female_sad\n",
       "130     male_angry      male_angry\n",
       "707     female_sad      female_sad\n",
       "1498    female_sad      female_sad\n",
       "1742     male_calm       male_calm\n",
       "310      male_calm       male_calm"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"-------COMMANDS-------\\nplay music (This automatically plays music base on your mood)\\nplay song_name (self choosen music or movie) \\n\\n--control playing song as-----\\npause\\nresume\\nstart again\")\n",
    "# print(\"to repeat song:REPLAY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing code section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwpath = ['../SER/output10.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting  recorded file\n",
    "# os.remove('../SER/testing.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../SER/output16.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Path\n",
       "0  ../SER/output16.wav"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newinput = pd.DataFrame({'Path': ['../SER/output16.wav']})\n",
    "newinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.85it/s]\n"
     ]
    }
   ],
   "source": [
    "n_mfcc = 30\n",
    "mfcc2 = prepare_data(newinput, n = n_mfcc, aug = 0, mfcc = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2 = model.predict(mfcc2, \n",
    "                         batch_size=16, \n",
    "                         verbose=1)\n",
    "\n",
    "preds2=preds2.argmax(axis=1)\n",
    "preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female_sad']\n"
     ]
    }
   ],
   "source": [
    "final = preds2.astype(int).flatten()\n",
    "final = (lb.inverse_transform((final)))\n",
    "print(final) #emo(final) #gender(final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getaudio():\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print('listei')\n",
    "        audio2 = recognizer.listen(source) \n",
    "    try:\n",
    "        s = recognizer.recognize_google(audio2,language=\"en\").lower()\n",
    "        print(s)\n",
    "        return s\n",
    "    except:\n",
    "        print('rtr')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Speak(text):\n",
    "    # Initialize the engine\n",
    "    engine = pt.init()\n",
    "    voice = engine.getProperty('voices')\n",
    "    engine.setProperty('voice',voice[1].id)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "Speak('kim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = 'play'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j\n"
     ]
    }
   ],
   "source": [
    "# if commands == 'turn on music':\n",
    "#     newinput = pd.DataFrame({'Path': '../SER/femi.wav'})    \n",
    "#     mfcc2 = prepare_data(newinput, n = n_mfcc, aug = 0, mfcc = 1)\n",
    "#     preds2 = model.predict(mfcc2, batch_size=16, verbose=1)\n",
    "#     preds2=preds2.argmax(axis=1)\n",
    "#     final = preds2.astype(int).flatten()\n",
    "#     final = (lb.inverse_transform((final)))\n",
    "#     print(final)\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a80a721eddef92e831e6e272c4656ac3b1576e9f7df1307f67eb40125234cad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
