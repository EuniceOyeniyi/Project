{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Installation\n",
    "# ! pip install SpeechRecognition\n",
    "# ! pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as srec\n",
    "import pyttsx3 as pt\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from nltk_utils import bag_of_words, tokenize, stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initialize the recognizer\n",
    "\n",
    "rec = srec.Recognizer()\n",
    "\n",
    "#  Creating a function to convert text to speech\n",
    "\n",
    "def ReadText(text):\n",
    "\n",
    "    # Initialize the engine\n",
    "    engine = pt.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# text= 'Hello Jola'\n",
    "# ReadText(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pipwin\n",
    "# ! pipwin install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silence please, calibrating background noise\n",
      "Calibrated, now speak ....\n",
      "Did you say i'm reading right now?\n"
     ]
    }
   ],
   "source": [
    "with srec.Microphone() as source:\n",
    "    print('Silence please, calibrating background noise')\n",
    "    rec.adjust_for_ambient_noise(source,duration=2)\n",
    "    print('Calibrated, now speak ....')\n",
    "\n",
    "    # Listening for user's input\n",
    "    audio2 = rec.listen(source)\n",
    "\n",
    "    # Using google to recognize audio\n",
    "    totext = rec.recognize_google(audio2)\n",
    "    totext = totext.lower()\n",
    "\n",
    "    print('Did you say '+totext+'?')\n",
    "    ReadText(totext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('interactions.json','r') as f:\n",
    "    interacts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'Hello', 'Hey', 'How', 'are', 'you', 'Is', 'anyone', 'there', 'Good', 'day', 'Good', 'Evening', 'Good', 'night', 'Good', 'morning', 'morning', 'Evening']\n",
      "['greetings']\n",
      "[(['Hi'], 'greetings'), (['Hello'], 'greetings'), (['Hey'], 'greetings'), (['How', 'are', 'you'], 'greetings'), (['Is', 'anyone', 'there'], 'greetings'), (['Good', 'day'], 'greetings'), (['Good', 'Evening'], 'greetings'), (['Good', 'night'], 'greetings'), (['Good', 'morning'], 'greetings'), (['morning'], 'greetings'), (['Evening'], 'greetings')]\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "patterns = []\n",
    "\n",
    "\n",
    "for interact in interacts['interaction']:\n",
    "    tag = interact['tag']\n",
    "    tags.append(tag)\n",
    "    for pattern in interact['pattern']:\n",
    "        word = tokenize(pattern)\n",
    "        all_words.extend(word)\n",
    "        patterns.append((word,tag))\n",
    "\n",
    "print(all_words)\n",
    "print(tags)\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Searching the internet with voice control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import webbrowser as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     path = \"C:/Program Files (x86)/Google/Chrome/Application/chrome.exe %%s\"\n",
    "#     with srec.Microphone() as source:\n",
    "        \n",
    "#         rec.adjust_for_ambient_noise(source,duration=2)\n",
    "#         print('Calibrated, now speak ....')\n",
    "\n",
    "#         # Listening for user's input\n",
    "#         audio2 = rec.listen(source)\n",
    "\n",
    "#         print('Recgonizing now ....')\n",
    "\n",
    "#         try:\n",
    "\n",
    "#             # Using google to recognize audio\n",
    "#             totext = rec.recognize_google(audio2)\n",
    "#             totext = totext.lower()\n",
    "\n",
    "#             print('Did you say '+totext+'?')\n",
    "#             web.get(path).open(totext)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(\"Error :\" + str(e))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a80a721eddef92e831e6e272c4656ac3b1576e9f7df1307f67eb40125234cad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
